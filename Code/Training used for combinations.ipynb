{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import kendalltau\n",
    "import os.path\n",
    "import winsound\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import loguniform\n",
    "import sys\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import os\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import os.path\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import xgboost as xgb\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.svm import SVC\n",
    "from pandas_profiling import ProfileReport\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from scipy.stats import pointbiserialr\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.cluster import KMeans\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from pandas_profiling import ProfileReport\n",
    "from scipy.stats import f_oneway, shapiro\n",
    "from io import BytesIO\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "import dtale\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "import matplotlib.cm\n",
    "import re\n",
    "import base64\n",
    "from scipy.stats import pointbiserialr, pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import category_encoders as ce\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "import winsound\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "np.set_printoptions(threshold=sys.maxsize, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After cleaning my initial dataset I saved the data into CSV format again so the cleaned and aligned dataset can act like original source for the other researchers who want to use this dataset.\n",
    "# Problem, is that saving it to CSV to not preserve datatypes, so I have to make them categorical again.\n",
    "datatypes = {'business_area': str, 'sex': str, 'employment_status': str,\n",
    "            'time': str, 'time_ESAW': str, 'severity': str, 'enterprise_size': str,\n",
    "            'citizenship': str, 'profession_code': str, 'type_of_injury': str\n",
    "            , 'injured_bodypart': str, 'workstation': str,\n",
    "            'working_environment': str, 'working_process': str\n",
    "            , 'specific_physical_activity': str,\n",
    "            'material_agent_of_physical_act.': str,\n",
    "            'deviation': str, 'material_agent_of_deviation': str\n",
    "            , 'contact_mode_of_injury': str, 'material_agent_of_contact_mode': str, 'general_profession_code': str, 'month': str, 'weekofyear': str, 'dayofweek': str, 'material_agent_of_physical_act': str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/Mario/OneDrive/Desktop/Final code for thesis')\n",
    "df = pd.read_csv(\"data.csv\", encoding='latin-1', dtype = datatypes, index_col=0)\n",
    "df = df.drop(columns= ['date', 'time', 'time_ESAW', 'datetime', 'lost_days', 'type_of_injury', 'injured_bodypart', 'severity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = list(df.business_sector.unique())\n",
    "classes = list(df.general_profession_class.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48845 entries, 0 to 48844\n",
      "Data columns (total 49 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   business_area                   48845 non-null  object \n",
      " 1   sex                             48845 non-null  object \n",
      " 2   age                             48845 non-null  float64\n",
      " 3   employment_status               48845 non-null  object \n",
      " 4   employment_years                48845 non-null  float64\n",
      " 5   full_hours_from_startofwork     48845 non-null  float64\n",
      " 6   location                        48845 non-null  object \n",
      " 7   citizenship                     48845 non-null  object \n",
      " 8   profession_code                 48845 non-null  object \n",
      " 9   workstation                     48845 non-null  object \n",
      " 10  working_environment             48845 non-null  object \n",
      " 11  working_process                 48845 non-null  object \n",
      " 12  specific_physical_activity      48845 non-null  object \n",
      " 13  material_agent_of_physical_act  48845 non-null  object \n",
      " 14  deviation                       48845 non-null  object \n",
      " 15  material_agent_of_deviation     48845 non-null  object \n",
      " 16  contact_mode_of_injury          48845 non-null  object \n",
      " 17  material_agent_of_contact_mode  48845 non-null  object \n",
      " 18  enterprise_size_ordinal_enc     48845 non-null  float64\n",
      " 19  business_sector                 48845 non-null  object \n",
      " 20  dayofweek                       48845 non-null  object \n",
      " 21  month                           48845 non-null  object \n",
      " 22  sin_time                        48845 non-null  float64\n",
      " 23  cos_time                        48845 non-null  float64\n",
      " 24  is_business_hour                48845 non-null  int64  \n",
      " 25  target                          48845 non-null  int64  \n",
      " 26  temperature                     48845 non-null  float64\n",
      " 27  rain                            48845 non-null  int64  \n",
      " 28  snowfall                        48845 non-null  int64  \n",
      " 29  cause code 001                  48845 non-null  int64  \n",
      " 30  cause code 002                  48845 non-null  int64  \n",
      " 31  cause code 003                  48845 non-null  int64  \n",
      " 32  cause code 004                  48845 non-null  int64  \n",
      " 33  cause code 005                  48845 non-null  int64  \n",
      " 34  cause code 006                  48845 non-null  int64  \n",
      " 35  cause code 007                  48845 non-null  int64  \n",
      " 36  cause code 008                  48845 non-null  int64  \n",
      " 37  cause code 009                  48845 non-null  int64  \n",
      " 38  cause code 010                  48845 non-null  int64  \n",
      " 39  cause code 011                  48845 non-null  int64  \n",
      " 40  cause code 012                  48845 non-null  int64  \n",
      " 41  cause code 013                  48845 non-null  int64  \n",
      " 42  cause code 014                  48845 non-null  int64  \n",
      " 43  cause code 015                  48845 non-null  int64  \n",
      " 44  cause code 017                  48845 non-null  int64  \n",
      " 45  cause code 018                  48845 non-null  int64  \n",
      " 46  cause code 019                  48845 non-null  int64  \n",
      " 47  cause code 025                  48845 non-null  int64  \n",
      " 48  general_profession_class        48845 non-null  int64  \n",
      "dtypes: float64(7), int64(24), object(18)\n",
      "memory usage: 18.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin of error: PASS for C9\n",
      "Salvestasin excelisse: C9\n",
      "Salvestasin excelisse: C9\n",
      "Salvestasin excelisse: C9\n",
      "Salvestasin excelisse: C9\n",
      "Salvestasin excelisse: C9\n",
      "Margin of error: PASS for C7\n",
      "Salvestasin excelisse: C7\n",
      "Salvestasin excelisse: C7\n",
      "Salvestasin excelisse: C7\n",
      "Salvestasin excelisse: C7\n",
      "Salvestasin excelisse: C7\n",
      "Margin of error: FAIL for C3\n",
      "Margin of error: PASS for C8\n",
      "Salvestasin excelisse: C8\n",
      "Salvestasin excelisse: C8\n",
      "Salvestasin excelisse: C8\n",
      "Salvestasin excelisse: C8\n",
      "Salvestasin excelisse: C8\n",
      "Margin of error: FAIL for C4\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: C and class: 0\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: D and class: 4\n",
      "Not enough positive samples for sector: D and class: 5\n",
      "Margin of error: PASS for D2\n",
      "An error occurred in SMOTE balancing: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6\n",
      "Not enough positive samples for sector: D and class: 1\n",
      "Not enough positive samples for sector: D and class: 6\n",
      "Not enough positive samples for sector: D and class: 0\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for B7\n",
      "Margin of error: FAIL for B3\n",
      "Margin of error: FAIL for B8\n",
      "Not enough positive samples for sector: B and class: 4\n",
      "Not enough positive samples for sector: B and class: 5\n",
      "Not enough positive samples for sector: B and class: 2\n",
      "Not enough positive samples for sector: B and class: 1\n",
      "Not enough positive samples for sector: B and class: 6\n",
      "Not enough positive samples for sector: B and class: 0\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for A3\n",
      "Margin of error: FAIL for A8\n",
      "Not enough positive samples for sector: A and class: 4\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for A2\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: PASS for A6\n",
      "Salvestasin excelisse: A6\n",
      "Salvestasin excelisse: A6\n",
      "Salvestasin excelisse: A6\n",
      "Salvestasin excelisse: A6\n",
      "Salvestasin excelisse: A6\n",
      "Not enough positive samples for sector: A and class: 0\n",
      "Margin of error: FAIL for M9\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for M3\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: M and class: 4\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: M and class: 6\n",
      "Not enough positive samples for sector: M and class: 0\n",
      "Margin of error: PASS for H9\n",
      "Salvestasin excelisse: H9\n",
      "Salvestasin excelisse: H9\n",
      "Salvestasin excelisse: H9\n",
      "Salvestasin excelisse: H9\n",
      "Salvestasin excelisse: H9\n",
      "Margin of error: FAIL for H7\n",
      "Margin of error: FAIL for H3\n",
      "Margin of error: PASS for H8\n",
      "Salvestasin excelisse: H8\n",
      "Salvestasin excelisse: H8\n",
      "Salvestasin excelisse: H8\n",
      "Salvestasin excelisse: H8\n",
      "Salvestasin excelisse: H8\n",
      "Margin of error: PASS for H4\n",
      "Salvestasin excelisse: H4\n",
      "Salvestasin excelisse: H4\n",
      "Salvestasin excelisse: H4\n",
      "Salvestasin excelisse: H4\n",
      "Salvestasin excelisse: H4\n",
      "Margin of error: FAIL for H5\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for H1\n",
      "Not enough positive samples for sector: H and class: 6\n",
      "Not enough positive samples for sector: H and class: 0\n",
      "Margin of error: PASS for G9\n",
      "Salvestasin excelisse: G9\n",
      "Salvestasin excelisse: G9\n",
      "Salvestasin excelisse: G9\n",
      "Salvestasin excelisse: G9\n",
      "Salvestasin excelisse: G9\n",
      "Margin of error: PASS for G7\n",
      "Salvestasin excelisse: G7\n",
      "Salvestasin excelisse: G7\n",
      "Salvestasin excelisse: G7\n",
      "Salvestasin excelisse: G7\n",
      "Salvestasin excelisse: G7\n",
      "Margin of error: FAIL for G3\n",
      "Margin of error: PASS for G8\n",
      "Salvestasin excelisse: G8\n",
      "Salvestasin excelisse: G8\n",
      "Salvestasin excelisse: G8\n",
      "Salvestasin excelisse: G8\n",
      "Salvestasin excelisse: G8\n",
      "Margin of error: FAIL for G4\n",
      "Margin of error: PASS for G5\n",
      "Salvestasin excelisse: G5\n",
      "Salvestasin excelisse: G5\n",
      "Salvestasin excelisse: G5\n",
      "Salvestasin excelisse: G5\n",
      "Salvestasin excelisse: G5\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for G1\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: G and class: 0\n",
      "Margin of error: FAIL for Q9\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: PASS for Q3\n",
      "Salvestasin excelisse: Q3\n",
      "Salvestasin excelisse: Q3\n",
      "Salvestasin excelisse: Q3\n",
      "Salvestasin excelisse: Q3\n",
      "Salvestasin excelisse: Q3\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: PASS for Q5\n",
      "Salvestasin excelisse: Q5\n",
      "Salvestasin excelisse: Q5\n",
      "Salvestasin excelisse: Q5\n",
      "Salvestasin excelisse: Q5\n",
      "Salvestasin excelisse: Q5\n",
      "Margin of error: PASS for Q2\n",
      "Salvestasin excelisse: Q2\n",
      "Salvestasin excelisse: Q2\n",
      "Salvestasin excelisse: Q2\n",
      "Salvestasin excelisse: Q2\n",
      "Salvestasin excelisse: Q2\n",
      "Margin of error: FAIL for Q1\n",
      "Not enough positive samples for sector: Q and class: 6\n",
      "Not enough positive samples for sector: Q and class: 0\n",
      "Margin of error: PASS for I9\n",
      "Salvestasin excelisse: I9\n",
      "Salvestasin excelisse: I9\n",
      "Salvestasin excelisse: I9\n",
      "Salvestasin excelisse: I9\n",
      "Salvestasin excelisse: I9\n",
      "Margin of error: FAIL for I7\n",
      "Not enough positive samples for sector: I and class: 3\n",
      "Not enough positive samples for sector: I and class: 8\n",
      "Margin of error: FAIL for I4\n",
      "Margin of error: PASS for I5\n",
      "Salvestasin excelisse: I5\n",
      "Salvestasin excelisse: I5\n",
      "Salvestasin excelisse: I5\n",
      "Salvestasin excelisse: I5\n",
      "Salvestasin excelisse: I5\n",
      "Not enough positive samples for sector: I and class: 2\n",
      "Margin of error: PASS for I1\n",
      "Skipping Random Forest for I1 due to only one class present in y_test\n",
      "Skipping LightGBM for I1 due to only one class present in y_test\n",
      "Skipping XGBoost for I1 due to only one class present in y_test\n",
      "Skipping SVM for I1 due to only one class present in y_test\n",
      "Skipping Logistic Regression for I1 due to only one class present in y_test\n",
      "Not enough positive samples for sector: I and class: 6\n",
      "Not enough positive samples for sector: I and class: 0\n",
      "Not enough positive samples for sector: K and class: 9\n",
      "Not enough positive samples for sector: K and class: 7\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: K and class: 8\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for K2\n",
      "Not enough positive samples for sector: K and class: 1\n",
      "Not enough positive samples for sector: K and class: 6\n",
      "Not enough positive samples for sector: K and class: 0\n",
      "Margin of error: FAIL for L9\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for L3\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: L and class: 2\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: L and class: 6\n",
      "Not enough positive samples for sector: L and class: 0\n",
      "Margin of error: PASS for N9\n",
      "Salvestasin excelisse: N9\n",
      "Salvestasin excelisse: N9\n",
      "Salvestasin excelisse: N9\n",
      "Salvestasin excelisse: N9\n",
      "Salvestasin excelisse: N9\n",
      "Margin of error: FAIL for N7\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for N4\n",
      "Margin of error: PASS for N5\n",
      "Salvestasin excelisse: N5\n",
      "Salvestasin excelisse: N5\n",
      "Salvestasin excelisse: N5\n",
      "Salvestasin excelisse: N5\n",
      "Salvestasin excelisse: N5\n",
      "Not enough positive samples for sector: N and class: 2\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for N6\n",
      "Not enough positive samples for sector: N and class: 0\n",
      "Margin of error: PASS for F9\n",
      "Salvestasin excelisse: F9\n",
      "Salvestasin excelisse: F9\n",
      "Salvestasin excelisse: F9\n",
      "Salvestasin excelisse: F9\n",
      "Salvestasin excelisse: F9\n",
      "Margin of error: PASS for F7\n",
      "Salvestasin excelisse: F7\n",
      "Salvestasin excelisse: F7\n",
      "Salvestasin excelisse: F7\n",
      "Salvestasin excelisse: F7\n",
      "Salvestasin excelisse: F7\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for F8\n",
      "Not enough positive samples for sector: F and class: 4\n",
      "Not enough positive samples for sector: F and class: 5\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: F and class: 6\n",
      "Not enough positive samples for sector: F and class: 0\n",
      "Margin of error: FAIL for O9\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: PASS for O3\n",
      "Salvestasin excelisse: O3\n",
      "Salvestasin excelisse: O3\n",
      "Salvestasin excelisse: O3\n",
      "Salvestasin excelisse: O3\n",
      "Salvestasin excelisse: O3\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for O4\n",
      "Margin of error: PASS for O5\n",
      "Salvestasin excelisse: O5\n",
      "Salvestasin excelisse: O5\n",
      "Salvestasin excelisse: O5\n",
      "Salvestasin excelisse: O5\n",
      "Salvestasin excelisse: O5\n",
      "Margin of error: FAIL for O2\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: PASS for O0\n",
      "Salvestasin excelisse: O0\n",
      "Salvestasin excelisse: O0\n",
      "Salvestasin excelisse: O0\n",
      "Salvestasin excelisse: O0\n",
      "Salvestasin excelisse: O0\n",
      "Margin of error: FAIL for P9\n",
      "Margin of error: FAIL for P7\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: P and class: 8\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for P5\n",
      "Margin of error: PASS for P2\n",
      "Salvestasin excelisse: P2\n",
      "Salvestasin excelisse: P2\n",
      "Salvestasin excelisse: P2\n",
      "Salvestasin excelisse: P2\n",
      "Salvestasin excelisse: P2\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: PASS for P6\n",
      "An error occurred in SMOTE balancing: Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 6\n",
      "Not enough positive samples for sector: P and class: 0\n",
      "Not enough positive samples for sector: J and class: 9\n",
      "Margin of error: FAIL for J7\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: J and class: 8\n",
      "Not enough positive samples for sector: J and class: 4\n",
      "Not enough positive samples for sector: J and class: 5\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: J and class: 6\n",
      "Not enough positive samples for sector: J and class: 0\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for S3\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: S and class: 4\n",
      "Margin of error: FAIL for S5\n",
      "Margin of error: FAIL for S2\n",
      "Margin of error: FAIL for S1\n",
      "Not enough positive samples for sector: S and class: 6\n",
      "Not enough positive samples for sector: S and class: 0\n",
      "Margin of error: FAIL for E9\n",
      "Margin of error: FAIL for E7\n",
      "Margin of error: FAIL for E3\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: E and class: 4\n",
      "An error occurred: at least one array or dtype is required\n",
      "Not enough positive samples for sector: E and class: 2\n",
      "Not enough positive samples for sector: E and class: 1\n",
      "Not enough positive samples for sector: E and class: 6\n",
      "Not enough positive samples for sector: E and class: 0\n",
      "An error occurred: at least one array or dtype is required\n",
      "An error occurred: at least one array or dtype is required\n",
      "Margin of error: FAIL for R3\n",
      "Margin of error: PASS for R8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=5 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-b05dd79736fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0mcv_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    871\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m                 \u001b[0mislice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# pre_dispatch and n_jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         iterable_with_config = (\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0m_with_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    350\u001b[0m             )\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Mario\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mmin_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0my_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    696\u001b[0m                 \u001b[1;34m\"n_splits=%d cannot be greater than the\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m                 \u001b[1;34m\" number of members in each class.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: n_splits=5 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "dff = df.copy()\n",
    "for f in sectors:\n",
    "\n",
    "    for e in classes:\n",
    "        \n",
    "        df = dff.copy()\n",
    "        df = df[(df['business_sector'] == f)]\n",
    "        df = df[(df['general_profession_class'] == e)]\n",
    "        if (df['target'] == 1).sum() < 5:\n",
    "            print('Not enough positive samples for sector: ' + f + ' and class: ' + str(e))\n",
    "            continue\n",
    "        df_sub = df.drop(columns=['business_sector', 'general_profession_class'])\n",
    "\n",
    "        df_sub_copy = df_sub.copy()\n",
    "\n",
    "        # --------------------------------------------------------------------------------\n",
    "        #TRAINING ON SIGNIFICANT FEATURES\n",
    "        # --------------------------------------------------------------------------------\n",
    "\n",
    "        def encode_categorical(df, categorical_columns):\n",
    "            le = LabelEncoder()\n",
    "            for col in categorical_columns:\n",
    "                df[col] = le.fit_transform(df[col])\n",
    "            return df\n",
    "\n",
    "        categorical_columns = df_sub.select_dtypes(include='object').columns.tolist()\n",
    "        df_encoded = encode_categorical(df_sub, categorical_columns)\n",
    "\n",
    "        # Get the column names with 'int32' and 'int64' dtypes\n",
    "        int32_columns = df_encoded.select_dtypes(include='int32').columns.tolist()\n",
    "        int64_columns = df_encoded.select_dtypes(include='int64').columns.tolist()\n",
    "\n",
    "        # Combine the two lists to create the categorical_columns list\n",
    "        categorical_columns = int32_columns + int64_columns\n",
    "\n",
    "        def chi_squared_test(df, target, categorical_columns):\n",
    "            significant_features = []\n",
    "            for col in categorical_columns:\n",
    "                contingency_table = pd.crosstab(df[col], df[target])\n",
    "                chi2, p_value, _, _ = stats.chi2_contingency(contingency_table)\n",
    "                \n",
    "                if p_value < 0.05:\n",
    "                    significant_features.append(col)\n",
    "            \n",
    "            return significant_features\n",
    "\n",
    "        significant_chi2_features = chi_squared_test(df_encoded, 'target', categorical_columns)\n",
    "\n",
    "\n",
    "        def kendall_correlation(df, target, numerical_columns):\n",
    "            significant_features = []\n",
    "            for col in numerical_columns:\n",
    "                kendall_tau, p_value = stats.kendalltau(df[col], df[target])\n",
    "                \n",
    "                if p_value < 0.05:\n",
    "                    significant_features.append(col)\n",
    "            \n",
    "            return significant_features\n",
    "\n",
    "        numerical_columns = df_sub.select_dtypes(include='float64').columns.tolist()\n",
    "        significant_kendall_features = kendall_correlation(df_sub, 'target', numerical_columns)\n",
    "\n",
    "        significant_features = significant_chi2_features + significant_kendall_features\n",
    "\n",
    "        df = df_sub_copy[significant_features]\n",
    "\n",
    "        # Encode categorical features with no order\n",
    "        all_object_cols = list(df.select_dtypes(include=['object']).columns)\n",
    "        df = pd.get_dummies(df, columns=all_object_cols)\n",
    "\n",
    "        # Separate independent variables and dependent variable for train set\n",
    "        X = df.drop(columns=['target'])\n",
    "        y = df['target']\n",
    "\n",
    "        # Balance the target class using random over-sampling\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        try:\n",
    "            float_cols = X_train.select_dtypes(include='float64').columns.tolist()\n",
    "            scaler = MinMaxScaler(feature_range=(0,1))\n",
    "            X_train[float_cols] = scaler.fit_transform(X_train[float_cols])\n",
    "            X_test[float_cols] = scaler.transform(X_test[float_cols])\n",
    "        except ValueError as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "\n",
    "        feat = 'significant_features'\n",
    "\n",
    "        # ----------------------------------------------------------------------------\n",
    "        #TRAINING ON ALL FEATURES\n",
    "        # ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        # Encode categorical features with no order\n",
    "        \"\"\" all_object_cols = list(df.select_dtypes(include=['object']).columns)\n",
    "        df = pd.get_dummies(df, columns=all_object_cols)\n",
    "\n",
    "        # Separate independent variables and dependent variable for train set\n",
    "        X = df.drop(columns=['target'])\n",
    "        y = df['target']\n",
    "\n",
    "        # Balance the target class using random over-sampling\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale float64 variables\n",
    "        float_cols = X_train.select_dtypes(include='float64').columns.tolist()\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        X_train[float_cols] = scaler.fit_transform(X_train[float_cols])\n",
    "        X_test[float_cols] = scaler.transform(X_test[float_cols])\n",
    "\n",
    "\n",
    "        feat = 'all_features' \"\"\"\n",
    "\n",
    "        # ---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        nr_of_independent_var = len(X_train.columns)\n",
    "        independent_var_names = [col for col in X_train.columns if col != 'target']\n",
    "        target_0 = y_train.value_counts()[0]\n",
    "        target_1 = y_train.value_counts()[1]\n",
    "\n",
    "        # Calculate the proportion of positive target class in the y_test data\n",
    "        positive_class_count = y_test.sum()\n",
    "        total_count = len(y_test)\n",
    "        proportion = positive_class_count / total_count\n",
    "\n",
    "        # Calculate the 95% confidence interval for the proportion\n",
    "        z = stats.norm.ppf(0.975)  # 95% confidence level\n",
    "        margin_of_error = z * np.sqrt((proportion * (1 - proportion)) / total_count)\n",
    "        confidence_interval = (proportion - margin_of_error, proportion + margin_of_error)\n",
    "\n",
    "        # Define a threshold for an acceptable margin of error (you can adjust this value)\n",
    "        acceptable_margin_of_error = 0.1\n",
    "\n",
    "        # Print evaluation sentence\n",
    "        if margin_of_error <= acceptable_margin_of_error:\n",
    "            print(f\"Margin of error: PASS for {f}{e}\")\n",
    "        else:\n",
    "            print(f\"Margin of error: FAIL for {f}{e}\")\n",
    "            continue\n",
    "    \n",
    "        \"\"\" over_sampler = RandomOverSampler(random_state=42)\n",
    "        X_train, y_train = over_sampler.fit_resample(X_train, y_train)\n",
    "        balancing_tech = 'ROS' \"\"\"\n",
    "        \n",
    "        \"\"\" under_sampler = RandomUnderSampler(random_state=42)\n",
    "        X_train, y_train = under_sampler.fit_resample(X_train, y_train)\n",
    "        balancing_tech = 'RUS' \"\"\"\n",
    "\n",
    "        try:\n",
    "            smote = SMOTE(random_state=rs)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "            balancing_tech = 'SMOTE'\n",
    "        except ValueError as e:\n",
    "            print(f\"An error occurred in SMOTE balancing: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "          # Check if the Excel file already exists\n",
    "        file_exists = os.path.isfile(f'combinations_{feat}_{balancing_tech}.xlsx')\n",
    "\n",
    "        # If the file doesn't exist, create a new DataFrame to store the results\n",
    "        if not file_exists:\n",
    "            results_df = pd.DataFrame(columns=[\n",
    "                \"Sector\",\n",
    "                \"Class\",\n",
    "                \"Nr_of_ind._var\",\n",
    "                \"Names_of_ind._var\",\n",
    "                \"Target_0_count\",\n",
    "                \"Target_1_count\",\n",
    "                \"Model_name\",\n",
    "                \"Balancing_tech.\",\n",
    "                \"AUCROC\",\n",
    "                \"CV_AUCROC\",\n",
    "                \"CV_AUCROC_std\",\n",
    "                \"AVG_F1\",\n",
    "                \"F1_score_0\",\n",
    "                \"F1_score_1\",\n",
    "                \"Precision_0\",\n",
    "                \"Precision_1\",\n",
    "                \"Recall_0\",\n",
    "                \"Recall_1\",\n",
    "            ])\n",
    "        else:\n",
    "            # If the file exists, load the existing DataFrame from the file\n",
    "            results_df = pd.read_excel(f'combinations_{feat}_{balancing_tech}.xlsx')\n",
    "\n",
    "        rs = 42\n",
    "        rf_model = RandomForestClassifier(random_state=rs)\n",
    "        lgbm_model = LGBMClassifier(random_state=rs)\n",
    "        svm_model = SVC(kernel='rbf', probability=True, random_state=rs)\n",
    "        xgb_model = xgb.XGBClassifier(random_state=rs)\n",
    "        lr_model = LogisticRegression(max_iter=1000, random_state=rs)\n",
    "\n",
    "        models = [rf_model, lgbm_model, xgb_model, svm_model, lr_model]\n",
    "        model_names = ['Random Forest', 'LightGBM', 'XGBoost', 'SVM', 'Logistic Regression']\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rs)   \n",
    "\n",
    "        for k, model in enumerate(models):\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_prob = model.predict_proba(X_test)[:,1]\n",
    "            \n",
    "            try:\n",
    "                auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "            except ValueError:\n",
    "                print(f\"Skipping {model_names[k]} for {f}{e} due to only one class present in y_test\")\n",
    "                continue\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            report = classification_report(y_test, y_pred)\n",
    "            auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "            f1_class_0 = f1_score(y_test, y_pred, pos_label=0)\n",
    "            f1_class_1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "            avg_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            precision_class_0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "            precision_class_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "            recall_class_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "            recall_class_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "            try:\n",
    "                balancing_tech = balancing_tech\n",
    "            except NameError:\n",
    "                balancing_tech = None\n",
    "            try:\n",
    "                comment1 = comment1\n",
    "            except NameError:\n",
    "                comment1 = None\n",
    "            # Create a dictionary of results\n",
    "            result = {\n",
    "                \"Sector\": f,\n",
    "                \"Class\": e,\n",
    "                \"Nr_of_ind._var\": nr_of_independent_var,\n",
    "                \"Names_of_ind._var\": \", \".join(independent_var_names),\n",
    "                \"Target_0_count\": target_0,\n",
    "                \"Target_1_count\": target_1,\n",
    "                \"Model_name\": model_names[k],\n",
    "                \"Balancing_tech.\": balancing_tech,\n",
    "                \"AUCROC\": auc_roc,\n",
    "                \"CV_AUCROC\": np.mean(cv_scores),\n",
    "                \"CV_AUCROC_std\": np.std(cv_scores),\n",
    "                \"AVG_F1\": avg_f1,\n",
    "                \"F1_score_0\": f1_class_0,\n",
    "                \"F1_score_1\": f1_class_1,\n",
    "                \"Precision_0\": precision_class_0,\n",
    "                \"Precision_1\": precision_class_1,\n",
    "                \"Recall_0\": recall_class_0,\n",
    "                \"Recall_1\": recall_class_1\n",
    "            }\n",
    "\n",
    "            # Append the result to the results DataFrame\n",
    "            results_df = pd.concat([results_df, pd.DataFrame(result, index=[0])], ignore_index=True)\n",
    "            print(f\"Salvestasin excelisse: {f}{e}\")\n",
    "            # Save the results DataFrame to the Excel file\n",
    "            results_df.to_excel(f'combinations_{feat}_{balancing_tech}.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
